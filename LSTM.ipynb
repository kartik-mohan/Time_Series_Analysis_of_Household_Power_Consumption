{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartik-mohan/Time_Series_Analysis_of_Household_Power_Consumption/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "x-Jj1ldWiNCH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4gjVczoLDFL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgPilMc6vYrE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split                              # to split the data into two parts\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import metrics                                                       # for the check the error and accuracy of the model\n",
        "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error,mean_absolute_percentage_error"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4kWlGlUwqJn"
      },
      "source": [
        "## for Deep-learing:\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Liw_fK5hOHXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0d15c6-94cf-4e54-e020-edc871a2ffcd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "NnxzofYIilol"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDLHF7DQB52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9d1e6d04-1794-402e-a132-b7b33d502817"
      },
      "source": [
        "# importing dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/SML_project/household_power_consumption.txt', sep=\";\", parse_dates={'dt' : ['Date', 'Time']}, infer_datetime_format=True, low_memory=False, na_values=['nan','?'], index_col='dt')\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:24:00</th>\n",
              "      <td>4.216</td>\n",
              "      <td>0.418</td>\n",
              "      <td>234.84</td>\n",
              "      <td>18.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:25:00</th>\n",
              "      <td>5.360</td>\n",
              "      <td>0.436</td>\n",
              "      <td>233.63</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:26:00</th>\n",
              "      <td>5.374</td>\n",
              "      <td>0.498</td>\n",
              "      <td>233.29</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:27:00</th>\n",
              "      <td>5.388</td>\n",
              "      <td>0.502</td>\n",
              "      <td>233.74</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:28:00</th>\n",
              "      <td>3.666</td>\n",
              "      <td>0.528</td>\n",
              "      <td>235.68</td>\n",
              "      <td>15.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Global_active_power  ...  Sub_metering_3\n",
              "dt                                        ...                \n",
              "2006-12-16 17:24:00                4.216  ...            17.0\n",
              "2006-12-16 17:25:00                5.360  ...            16.0\n",
              "2006-12-16 17:26:00                5.374  ...            17.0\n",
              "2006-12-16 17:27:00                5.388  ...            17.0\n",
              "2006-12-16 17:28:00                3.666  ...            17.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biOrZGQ7V0PQ",
        "outputId": "bdd3c348-6b69-41e3-aba4-95e71563b90f"
      },
      "source": [
        "df = df.fillna(method='ffill')\n",
        "df.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Global_active_power      0\n",
              "Global_reactive_power    0\n",
              "Voltage                  0\n",
              "Global_intensity         0\n",
              "Sub_metering_1           0\n",
              "Sub_metering_2           0\n",
              "Sub_metering_3           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['energy_consumed'] = (df['Global_active_power'] * 1000 / 60) - (df['Sub_metering_1'] + df['Sub_metering_2'] + df['Sub_metering_3'])"
      ],
      "metadata": {
        "id": "vy5TXQqjCkgZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spaullsjaDan",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ac23d585-3ee5-4b6d-9f38-3030b7d6bcc9"
      },
      "source": [
        "data_resampled = df.resample('SM').sum()\n",
        "data_resampled.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "      <th>energy_consumed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-12-15</th>\n",
              "      <td>38332.010</td>\n",
              "      <td>2739.412</td>\n",
              "      <td>4965281.53</td>\n",
              "      <td>161961.8</td>\n",
              "      <td>27536.0</td>\n",
              "      <td>48403.0</td>\n",
              "      <td>156485.0</td>\n",
              "      <td>406442.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-31</th>\n",
              "      <td>34634.820</td>\n",
              "      <td>3090.402</td>\n",
              "      <td>5195859.08</td>\n",
              "      <td>146674.4</td>\n",
              "      <td>19277.0</td>\n",
              "      <td>36935.0</td>\n",
              "      <td>144067.0</td>\n",
              "      <td>376968.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-01-15</th>\n",
              "      <td>35512.854</td>\n",
              "      <td>2797.424</td>\n",
              "      <td>5558097.23</td>\n",
              "      <td>150307.0</td>\n",
              "      <td>37156.0</td>\n",
              "      <td>36736.0</td>\n",
              "      <td>176994.0</td>\n",
              "      <td>340994.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-01-31</th>\n",
              "      <td>34341.684</td>\n",
              "      <td>2543.752</td>\n",
              "      <td>5194277.02</td>\n",
              "      <td>144951.6</td>\n",
              "      <td>29936.0</td>\n",
              "      <td>40371.0</td>\n",
              "      <td>172991.0</td>\n",
              "      <td>329063.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-02-15</th>\n",
              "      <td>23996.272</td>\n",
              "      <td>2110.592</td>\n",
              "      <td>4500232.82</td>\n",
              "      <td>101306.6</td>\n",
              "      <td>17648.0</td>\n",
              "      <td>29843.0</td>\n",
              "      <td>110396.0</td>\n",
              "      <td>242050.866667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Global_active_power  ...  energy_consumed\n",
              "dt                               ...                 \n",
              "2006-12-15            38332.010  ...    406442.833333\n",
              "2006-12-31            34634.820  ...    376968.000000\n",
              "2007-01-15            35512.854  ...    340994.900000\n",
              "2007-01-31            34341.684  ...    329063.400000\n",
              "2007-02-15            23996.272  ...    242050.866667\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9iqoDubgH2x"
      },
      "source": [
        "Converting time series into supervised machine learning problem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdff = pd.DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(dff.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(dff.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = pd.concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "metadata": {
        "id": "lYyf_yHi8UFm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx6894jvH1bw"
      },
      "source": [
        "#### Feature Scaling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqoOFG_PHnEW"
      },
      "source": [
        "#Minmax standard scaling technique:\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(data_resampled.values)\n",
        "\n",
        "# frame as supervised learning\n",
        "data_reframed = series_to_supervised(scaled, 1, 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5m9aPHUIHRH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "50a2d6fa-ddcf-408b-94a8-9402157eb957"
      },
      "source": [
        "data_reframed.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var1(t-1)</th>\n",
              "      <th>var2(t-1)</th>\n",
              "      <th>var3(t-1)</th>\n",
              "      <th>var4(t-1)</th>\n",
              "      <th>var5(t-1)</th>\n",
              "      <th>var6(t-1)</th>\n",
              "      <th>var7(t-1)</th>\n",
              "      <th>var8(t-1)</th>\n",
              "      <th>var1(t)</th>\n",
              "      <th>var2(t)</th>\n",
              "      <th>var3(t)</th>\n",
              "      <th>var4(t)</th>\n",
              "      <th>var5(t)</th>\n",
              "      <th>var6(t)</th>\n",
              "      <th>var7(t)</th>\n",
              "      <th>var8(t)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.950534</td>\n",
              "      <td>0.352012</td>\n",
              "      <td>0.554706</td>\n",
              "      <td>0.963389</td>\n",
              "      <td>0.626331</td>\n",
              "      <td>0.939737</td>\n",
              "      <td>0.586722</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.847420</td>\n",
              "      <td>0.462026</td>\n",
              "      <td>0.705259</td>\n",
              "      <td>0.859667</td>\n",
              "      <td>0.438472</td>\n",
              "      <td>0.680222</td>\n",
              "      <td>0.531019</td>\n",
              "      <td>0.919942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.847420</td>\n",
              "      <td>0.462026</td>\n",
              "      <td>0.705259</td>\n",
              "      <td>0.859667</td>\n",
              "      <td>0.438472</td>\n",
              "      <td>0.680222</td>\n",
              "      <td>0.531019</td>\n",
              "      <td>0.919942</td>\n",
              "      <td>0.871909</td>\n",
              "      <td>0.370195</td>\n",
              "      <td>0.941778</td>\n",
              "      <td>0.884313</td>\n",
              "      <td>0.845146</td>\n",
              "      <td>0.675718</td>\n",
              "      <td>0.678720</td>\n",
              "      <td>0.822234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.871909</td>\n",
              "      <td>0.370195</td>\n",
              "      <td>0.941778</td>\n",
              "      <td>0.884313</td>\n",
              "      <td>0.845146</td>\n",
              "      <td>0.675718</td>\n",
              "      <td>0.678720</td>\n",
              "      <td>0.822234</td>\n",
              "      <td>0.839245</td>\n",
              "      <td>0.290684</td>\n",
              "      <td>0.704226</td>\n",
              "      <td>0.847978</td>\n",
              "      <td>0.680921</td>\n",
              "      <td>0.757977</td>\n",
              "      <td>0.660763</td>\n",
              "      <td>0.789826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.839245</td>\n",
              "      <td>0.290684</td>\n",
              "      <td>0.704226</td>\n",
              "      <td>0.847978</td>\n",
              "      <td>0.680921</td>\n",
              "      <td>0.757977</td>\n",
              "      <td>0.660763</td>\n",
              "      <td>0.789826</td>\n",
              "      <td>0.550714</td>\n",
              "      <td>0.154914</td>\n",
              "      <td>0.251057</td>\n",
              "      <td>0.551854</td>\n",
              "      <td>0.401419</td>\n",
              "      <td>0.519733</td>\n",
              "      <td>0.379980</td>\n",
              "      <td>0.553488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.550714</td>\n",
              "      <td>0.154914</td>\n",
              "      <td>0.251057</td>\n",
              "      <td>0.551854</td>\n",
              "      <td>0.401419</td>\n",
              "      <td>0.519733</td>\n",
              "      <td>0.379980</td>\n",
              "      <td>0.553488</td>\n",
              "      <td>0.567277</td>\n",
              "      <td>0.228134</td>\n",
              "      <td>0.707229</td>\n",
              "      <td>0.570262</td>\n",
              "      <td>0.607997</td>\n",
              "      <td>0.940032</td>\n",
              "      <td>0.388135</td>\n",
              "      <td>0.500320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   var1(t-1)  var2(t-1)  var3(t-1)  ...   var6(t)   var7(t)   var8(t)\n",
              "1   0.950534   0.352012   0.554706  ...  0.680222  0.531019  0.919942\n",
              "2   0.847420   0.462026   0.705259  ...  0.675718  0.678720  0.822234\n",
              "3   0.871909   0.370195   0.941778  ...  0.757977  0.660763  0.789826\n",
              "4   0.839245   0.290684   0.704226  ...  0.519733  0.379980  0.553488\n",
              "5   0.550714   0.154914   0.251057  ...  0.940032  0.388135  0.500320\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8tfBfYnIIl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3397f5fe-6655-42be-b07d-572932699cf0"
      },
      "source": [
        "# drop columns we don't want to predict\n",
        "data_reframed.drop(data_reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
        "print(data_reframed.head())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   var1(t-1)  var2(t-1)  var3(t-1)  ...  var7(t-1)  var8(t-1)   var1(t)\n",
            "1   0.950534   0.352012   0.554706  ...   0.586722   1.000000  0.847420\n",
            "2   0.847420   0.462026   0.705259  ...   0.531019   0.919942  0.871909\n",
            "3   0.871909   0.370195   0.941778  ...   0.678720   0.822234  0.839245\n",
            "4   0.839245   0.290684   0.704226  ...   0.660763   0.789826  0.550714\n",
            "5   0.550714   0.154914   0.251057  ...   0.379980   0.553488  0.567277\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sap0uEHDfC3U"
      },
      "source": [
        "### Splitting dataset to train and test:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_reframed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxHQDBhL9nRW",
        "outputId": "77215a15-c8e9-41dc-f07e-92ae0cfc1fc1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7isnLOlr8ofU"
      },
      "source": [
        "def split():\n",
        "  values = data_reframed.values\n",
        "\n",
        "  num_trains = 94-18\n",
        "  #train data\n",
        "  train = values[:num_trains, :]\n",
        "  #test data\n",
        "  test = values[num_trains:, :]\n",
        "\n",
        "  # split into train and test\n",
        "  train_X, train_y = train[:, :-1], train[:, -1]\n",
        "  test_X, test_y = test[:, :-1], test[:, -1]\n",
        "\n",
        "  # reshape input to be 3D [samples, timesteps, features]\n",
        "  train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "  test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "\n",
        "  return train_X, train_y, test_X, test_y"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Modeling"
      ],
      "metadata": {
        "id": "gMnhw_-Nl3hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}\n",
        "for unit in [30,50,100] :  \n",
        "  train_X, train_y, test_X, test_y = split()\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(unit, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "  # fit network\n",
        "  history = model.fit(train_X, train_y, epochs=100, batch_size=10, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "\n",
        "  # make a prediction\n",
        "  yhat = model.predict(test_X)\n",
        "  test_X = test_X.reshape((test_X.shape[0], 8))\n",
        "\n",
        "  # invert scaling for forecast\n",
        "  inv_yhat = np.concatenate((yhat, test_X[:, -7:]), axis=1)\n",
        "  inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "  inv_yhat = inv_yhat[:,0]\n",
        "\n",
        "  # invert scaling for actual\n",
        "  test_y = test_y.reshape((len(test_y), 1))\n",
        "  inv_y = np.concatenate((test_y, test_X[:, -7:]), axis=1)\n",
        "  inv_y = scaler.inverse_transform(inv_y)\n",
        "  inv_y = inv_y[:,0]\n",
        "  \n",
        "  # calculate RMSE\n",
        "  rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "  mse = mean_squared_error(inv_y, inv_yhat)\n",
        "  mae = mean_absolute_error(inv_y, inv_yhat)\n",
        "  r2 = r2_score(inv_y, inv_yhat)\n",
        "  mape = mean_absolute_percentage_error(inv_y, inv_yhat)\n",
        "\n",
        "  models[unit] = [rmse, mse, mae, r2, mape]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF3Ez-W7ANLJ",
        "outputId": "335b7af3-3063-473a-d07c-78f4628522cc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 - 3s - loss: 0.3208 - val_loss: 0.1806 - 3s/epoch - 361ms/step\n",
            "Epoch 2/100\n",
            "8/8 - 0s - loss: 0.2406 - val_loss: 0.1260 - 39ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "8/8 - 0s - loss: 0.1736 - val_loss: 0.0838 - 39ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "8/8 - 0s - loss: 0.1211 - val_loss: 0.0526 - 35ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "8/8 - 0s - loss: 0.0733 - val_loss: 0.0319 - 39ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "8/8 - 0s - loss: 0.0459 - val_loss: 0.0208 - 49ms/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "8/8 - 0s - loss: 0.0346 - val_loss: 0.0169 - 40ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "8/8 - 0s - loss: 0.0296 - val_loss: 0.0171 - 40ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "8/8 - 0s - loss: 0.0278 - val_loss: 0.0184 - 47ms/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "8/8 - 0s - loss: 0.0268 - val_loss: 0.0192 - 51ms/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "8/8 - 0s - loss: 0.0298 - val_loss: 0.0189 - 52ms/epoch - 7ms/step\n",
            "Epoch 12/100\n",
            "8/8 - 0s - loss: 0.0284 - val_loss: 0.0188 - 47ms/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "8/8 - 0s - loss: 0.0281 - val_loss: 0.0189 - 48ms/epoch - 6ms/step\n",
            "Epoch 14/100\n",
            "8/8 - 0s - loss: 0.0276 - val_loss: 0.0186 - 46ms/epoch - 6ms/step\n",
            "Epoch 15/100\n",
            "8/8 - 0s - loss: 0.0219 - val_loss: 0.0179 - 49ms/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "8/8 - 0s - loss: 0.0256 - val_loss: 0.0174 - 54ms/epoch - 7ms/step\n",
            "Epoch 17/100\n",
            "8/8 - 0s - loss: 0.0263 - val_loss: 0.0173 - 41ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "8/8 - 0s - loss: 0.0252 - val_loss: 0.0172 - 57ms/epoch - 7ms/step\n",
            "Epoch 19/100\n",
            "8/8 - 0s - loss: 0.0248 - val_loss: 0.0172 - 47ms/epoch - 6ms/step\n",
            "Epoch 20/100\n",
            "8/8 - 0s - loss: 0.0239 - val_loss: 0.0170 - 48ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "8/8 - 0s - loss: 0.0241 - val_loss: 0.0170 - 48ms/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "8/8 - 0s - loss: 0.0260 - val_loss: 0.0169 - 40ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "8/8 - 0s - loss: 0.0268 - val_loss: 0.0169 - 44ms/epoch - 6ms/step\n",
            "Epoch 24/100\n",
            "8/8 - 0s - loss: 0.0247 - val_loss: 0.0170 - 47ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "8/8 - 0s - loss: 0.0244 - val_loss: 0.0169 - 45ms/epoch - 6ms/step\n",
            "Epoch 26/100\n",
            "8/8 - 0s - loss: 0.0278 - val_loss: 0.0163 - 45ms/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "8/8 - 0s - loss: 0.0236 - val_loss: 0.0159 - 57ms/epoch - 7ms/step\n",
            "Epoch 28/100\n",
            "8/8 - 0s - loss: 0.0209 - val_loss: 0.0158 - 41ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "8/8 - 0s - loss: 0.0210 - val_loss: 0.0158 - 47ms/epoch - 6ms/step\n",
            "Epoch 30/100\n",
            "8/8 - 0s - loss: 0.0215 - val_loss: 0.0161 - 44ms/epoch - 6ms/step\n",
            "Epoch 31/100\n",
            "8/8 - 0s - loss: 0.0214 - val_loss: 0.0164 - 41ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "8/8 - 0s - loss: 0.0222 - val_loss: 0.0162 - 51ms/epoch - 6ms/step\n",
            "Epoch 33/100\n",
            "8/8 - 0s - loss: 0.0248 - val_loss: 0.0159 - 43ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "8/8 - 0s - loss: 0.0218 - val_loss: 0.0156 - 53ms/epoch - 7ms/step\n",
            "Epoch 35/100\n",
            "8/8 - 0s - loss: 0.0195 - val_loss: 0.0156 - 59ms/epoch - 7ms/step\n",
            "Epoch 36/100\n",
            "8/8 - 0s - loss: 0.0245 - val_loss: 0.0159 - 41ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "8/8 - 0s - loss: 0.0196 - val_loss: 0.0158 - 45ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "8/8 - 0s - loss: 0.0230 - val_loss: 0.0157 - 44ms/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "8/8 - 0s - loss: 0.0218 - val_loss: 0.0154 - 38ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "8/8 - 0s - loss: 0.0220 - val_loss: 0.0152 - 41ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "8/8 - 0s - loss: 0.0187 - val_loss: 0.0152 - 48ms/epoch - 6ms/step\n",
            "Epoch 42/100\n",
            "8/8 - 0s - loss: 0.0193 - val_loss: 0.0152 - 48ms/epoch - 6ms/step\n",
            "Epoch 43/100\n",
            "8/8 - 0s - loss: 0.0206 - val_loss: 0.0153 - 43ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "8/8 - 0s - loss: 0.0216 - val_loss: 0.0151 - 44ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "8/8 - 0s - loss: 0.0192 - val_loss: 0.0148 - 44ms/epoch - 6ms/step\n",
            "Epoch 46/100\n",
            "8/8 - 0s - loss: 0.0170 - val_loss: 0.0149 - 62ms/epoch - 8ms/step\n",
            "Epoch 47/100\n",
            "8/8 - 0s - loss: 0.0204 - val_loss: 0.0150 - 48ms/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "8/8 - 0s - loss: 0.0167 - val_loss: 0.0151 - 41ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "8/8 - 0s - loss: 0.0214 - val_loss: 0.0151 - 50ms/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "8/8 - 0s - loss: 0.0213 - val_loss: 0.0148 - 36ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "8/8 - 0s - loss: 0.0201 - val_loss: 0.0146 - 38ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "8/8 - 0s - loss: 0.0189 - val_loss: 0.0146 - 43ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "8/8 - 0s - loss: 0.0191 - val_loss: 0.0147 - 43ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "8/8 - 0s - loss: 0.0213 - val_loss: 0.0146 - 52ms/epoch - 6ms/step\n",
            "Epoch 55/100\n",
            "8/8 - 0s - loss: 0.0181 - val_loss: 0.0146 - 49ms/epoch - 6ms/step\n",
            "Epoch 56/100\n",
            "8/8 - 0s - loss: 0.0165 - val_loss: 0.0151 - 57ms/epoch - 7ms/step\n",
            "Epoch 57/100\n",
            "8/8 - 0s - loss: 0.0189 - val_loss: 0.0147 - 49ms/epoch - 6ms/step\n",
            "Epoch 58/100\n",
            "8/8 - 0s - loss: 0.0198 - val_loss: 0.0144 - 60ms/epoch - 7ms/step\n",
            "Epoch 59/100\n",
            "8/8 - 0s - loss: 0.0201 - val_loss: 0.0146 - 46ms/epoch - 6ms/step\n",
            "Epoch 60/100\n",
            "8/8 - 0s - loss: 0.0174 - val_loss: 0.0148 - 48ms/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "8/8 - 0s - loss: 0.0204 - val_loss: 0.0148 - 45ms/epoch - 6ms/step\n",
            "Epoch 62/100\n",
            "8/8 - 0s - loss: 0.0197 - val_loss: 0.0146 - 49ms/epoch - 6ms/step\n",
            "Epoch 63/100\n",
            "8/8 - 0s - loss: 0.0185 - val_loss: 0.0143 - 53ms/epoch - 7ms/step\n",
            "Epoch 64/100\n",
            "8/8 - 0s - loss: 0.0193 - val_loss: 0.0142 - 46ms/epoch - 6ms/step\n",
            "Epoch 65/100\n",
            "8/8 - 0s - loss: 0.0191 - val_loss: 0.0144 - 47ms/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "8/8 - 0s - loss: 0.0203 - val_loss: 0.0146 - 45ms/epoch - 6ms/step\n",
            "Epoch 67/100\n",
            "8/8 - 0s - loss: 0.0202 - val_loss: 0.0143 - 39ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "8/8 - 0s - loss: 0.0193 - val_loss: 0.0141 - 49ms/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "8/8 - 0s - loss: 0.0171 - val_loss: 0.0139 - 41ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "8/8 - 0s - loss: 0.0179 - val_loss: 0.0138 - 41ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "8/8 - 0s - loss: 0.0207 - val_loss: 0.0139 - 42ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "8/8 - 0s - loss: 0.0177 - val_loss: 0.0141 - 45ms/epoch - 6ms/step\n",
            "Epoch 73/100\n",
            "8/8 - 0s - loss: 0.0168 - val_loss: 0.0141 - 45ms/epoch - 6ms/step\n",
            "Epoch 74/100\n",
            "8/8 - 0s - loss: 0.0158 - val_loss: 0.0140 - 45ms/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "8/8 - 0s - loss: 0.0180 - val_loss: 0.0137 - 46ms/epoch - 6ms/step\n",
            "Epoch 76/100\n",
            "8/8 - 0s - loss: 0.0151 - val_loss: 0.0137 - 53ms/epoch - 7ms/step\n",
            "Epoch 77/100\n",
            "8/8 - 0s - loss: 0.0179 - val_loss: 0.0138 - 50ms/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "8/8 - 0s - loss: 0.0179 - val_loss: 0.0139 - 47ms/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "8/8 - 0s - loss: 0.0179 - val_loss: 0.0139 - 46ms/epoch - 6ms/step\n",
            "Epoch 80/100\n",
            "8/8 - 0s - loss: 0.0178 - val_loss: 0.0138 - 61ms/epoch - 8ms/step\n",
            "Epoch 81/100\n",
            "8/8 - 0s - loss: 0.0166 - val_loss: 0.0135 - 54ms/epoch - 7ms/step\n",
            "Epoch 82/100\n",
            "8/8 - 0s - loss: 0.0169 - val_loss: 0.0135 - 65ms/epoch - 8ms/step\n",
            "Epoch 83/100\n",
            "8/8 - 0s - loss: 0.0185 - val_loss: 0.0136 - 43ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "8/8 - 0s - loss: 0.0176 - val_loss: 0.0136 - 47ms/epoch - 6ms/step\n",
            "Epoch 85/100\n",
            "8/8 - 0s - loss: 0.0187 - val_loss: 0.0138 - 46ms/epoch - 6ms/step\n",
            "Epoch 86/100\n",
            "8/8 - 0s - loss: 0.0178 - val_loss: 0.0137 - 43ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "8/8 - 0s - loss: 0.0162 - val_loss: 0.0139 - 51ms/epoch - 6ms/step\n",
            "Epoch 88/100\n",
            "8/8 - 0s - loss: 0.0169 - val_loss: 0.0139 - 52ms/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "8/8 - 0s - loss: 0.0207 - val_loss: 0.0138 - 52ms/epoch - 6ms/step\n",
            "Epoch 90/100\n",
            "8/8 - 0s - loss: 0.0164 - val_loss: 0.0137 - 53ms/epoch - 7ms/step\n",
            "Epoch 91/100\n",
            "8/8 - 0s - loss: 0.0137 - val_loss: 0.0140 - 48ms/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "8/8 - 0s - loss: 0.0195 - val_loss: 0.0140 - 55ms/epoch - 7ms/step\n",
            "Epoch 93/100\n",
            "8/8 - 0s - loss: 0.0201 - val_loss: 0.0134 - 44ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "8/8 - 0s - loss: 0.0191 - val_loss: 0.0132 - 72ms/epoch - 9ms/step\n",
            "Epoch 95/100\n",
            "8/8 - 0s - loss: 0.0193 - val_loss: 0.0132 - 59ms/epoch - 7ms/step\n",
            "Epoch 96/100\n",
            "8/8 - 0s - loss: 0.0147 - val_loss: 0.0134 - 45ms/epoch - 6ms/step\n",
            "Epoch 97/100\n",
            "8/8 - 0s - loss: 0.0182 - val_loss: 0.0134 - 52ms/epoch - 6ms/step\n",
            "Epoch 98/100\n",
            "8/8 - 0s - loss: 0.0173 - val_loss: 0.0133 - 47ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "8/8 - 0s - loss: 0.0175 - val_loss: 0.0133 - 46ms/epoch - 6ms/step\n",
            "Epoch 100/100\n",
            "8/8 - 0s - loss: 0.0152 - val_loss: 0.0134 - 47ms/epoch - 6ms/step\n",
            "Epoch 1/100\n",
            "8/8 - 2s - loss: 0.2983 - val_loss: 0.1431 - 2s/epoch - 295ms/step\n",
            "Epoch 2/100\n",
            "8/8 - 0s - loss: 0.1791 - val_loss: 0.0793 - 37ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "8/8 - 0s - loss: 0.1082 - val_loss: 0.0391 - 42ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "8/8 - 0s - loss: 0.0587 - val_loss: 0.0200 - 42ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "8/8 - 0s - loss: 0.0313 - val_loss: 0.0164 - 44ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "8/8 - 0s - loss: 0.0223 - val_loss: 0.0195 - 56ms/epoch - 7ms/step\n",
            "Epoch 7/100\n",
            "8/8 - 0s - loss: 0.0219 - val_loss: 0.0216 - 52ms/epoch - 6ms/step\n",
            "Epoch 8/100\n",
            "8/8 - 0s - loss: 0.0234 - val_loss: 0.0209 - 54ms/epoch - 7ms/step\n",
            "Epoch 9/100\n",
            "8/8 - 0s - loss: 0.0239 - val_loss: 0.0192 - 50ms/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "8/8 - 0s - loss: 0.0243 - val_loss: 0.0179 - 45ms/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "8/8 - 0s - loss: 0.0228 - val_loss: 0.0171 - 50ms/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "8/8 - 0s - loss: 0.0239 - val_loss: 0.0170 - 40ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "8/8 - 0s - loss: 0.0225 - val_loss: 0.0171 - 40ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "8/8 - 0s - loss: 0.0203 - val_loss: 0.0172 - 52ms/epoch - 6ms/step\n",
            "Epoch 15/100\n",
            "8/8 - 0s - loss: 0.0230 - val_loss: 0.0171 - 44ms/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "8/8 - 0s - loss: 0.0223 - val_loss: 0.0172 - 49ms/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "8/8 - 0s - loss: 0.0206 - val_loss: 0.0171 - 51ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "8/8 - 0s - loss: 0.0224 - val_loss: 0.0171 - 57ms/epoch - 7ms/step\n",
            "Epoch 19/100\n",
            "8/8 - 0s - loss: 0.0201 - val_loss: 0.0168 - 46ms/epoch - 6ms/step\n",
            "Epoch 20/100\n",
            "8/8 - 0s - loss: 0.0225 - val_loss: 0.0165 - 47ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "8/8 - 0s - loss: 0.0187 - val_loss: 0.0161 - 46ms/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "8/8 - 0s - loss: 0.0206 - val_loss: 0.0161 - 39ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "8/8 - 0s - loss: 0.0190 - val_loss: 0.0161 - 52ms/epoch - 7ms/step\n",
            "Epoch 24/100\n",
            "8/8 - 0s - loss: 0.0204 - val_loss: 0.0158 - 50ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "8/8 - 0s - loss: 0.0208 - val_loss: 0.0158 - 37ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "8/8 - 0s - loss: 0.0191 - val_loss: 0.0161 - 43ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "8/8 - 0s - loss: 0.0209 - val_loss: 0.0159 - 49ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "8/8 - 0s - loss: 0.0177 - val_loss: 0.0160 - 57ms/epoch - 7ms/step\n",
            "Epoch 29/100\n",
            "8/8 - 0s - loss: 0.0195 - val_loss: 0.0155 - 49ms/epoch - 6ms/step\n",
            "Epoch 30/100\n",
            "8/8 - 0s - loss: 0.0191 - val_loss: 0.0150 - 53ms/epoch - 7ms/step\n",
            "Epoch 31/100\n",
            "8/8 - 0s - loss: 0.0185 - val_loss: 0.0147 - 52ms/epoch - 6ms/step\n",
            "Epoch 32/100\n",
            "8/8 - 0s - loss: 0.0223 - val_loss: 0.0146 - 57ms/epoch - 7ms/step\n",
            "Epoch 33/100\n",
            "8/8 - 0s - loss: 0.0172 - val_loss: 0.0148 - 53ms/epoch - 7ms/step\n",
            "Epoch 34/100\n",
            "8/8 - 0s - loss: 0.0205 - val_loss: 0.0152 - 45ms/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "8/8 - 0s - loss: 0.0203 - val_loss: 0.0152 - 46ms/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "8/8 - 0s - loss: 0.0185 - val_loss: 0.0150 - 56ms/epoch - 7ms/step\n",
            "Epoch 37/100\n",
            "8/8 - 0s - loss: 0.0167 - val_loss: 0.0147 - 59ms/epoch - 7ms/step\n",
            "Epoch 38/100\n",
            "8/8 - 0s - loss: 0.0211 - val_loss: 0.0145 - 50ms/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "8/8 - 0s - loss: 0.0185 - val_loss: 0.0144 - 56ms/epoch - 7ms/step\n",
            "Epoch 40/100\n",
            "8/8 - 0s - loss: 0.0194 - val_loss: 0.0142 - 56ms/epoch - 7ms/step\n",
            "Epoch 41/100\n",
            "8/8 - 0s - loss: 0.0176 - val_loss: 0.0142 - 50ms/epoch - 6ms/step\n",
            "Epoch 42/100\n",
            "8/8 - 0s - loss: 0.0169 - val_loss: 0.0143 - 61ms/epoch - 8ms/step\n",
            "Epoch 43/100\n",
            "8/8 - 0s - loss: 0.0173 - val_loss: 0.0145 - 54ms/epoch - 7ms/step\n",
            "Epoch 44/100\n",
            "8/8 - 0s - loss: 0.0160 - val_loss: 0.0144 - 50ms/epoch - 6ms/step\n",
            "Epoch 45/100\n",
            "8/8 - 0s - loss: 0.0159 - val_loss: 0.0145 - 52ms/epoch - 7ms/step\n",
            "Epoch 46/100\n",
            "8/8 - 0s - loss: 0.0166 - val_loss: 0.0144 - 56ms/epoch - 7ms/step\n",
            "Epoch 47/100\n",
            "8/8 - 0s - loss: 0.0173 - val_loss: 0.0143 - 63ms/epoch - 8ms/step\n",
            "Epoch 48/100\n",
            "8/8 - 0s - loss: 0.0183 - val_loss: 0.0143 - 47ms/epoch - 6ms/step\n",
            "Epoch 49/100\n",
            "8/8 - 0s - loss: 0.0186 - val_loss: 0.0141 - 47ms/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "8/8 - 0s - loss: 0.0169 - val_loss: 0.0141 - 62ms/epoch - 8ms/step\n",
            "Epoch 51/100\n",
            "8/8 - 0s - loss: 0.0173 - val_loss: 0.0141 - 45ms/epoch - 6ms/step\n",
            "Epoch 52/100\n",
            "8/8 - 0s - loss: 0.0189 - val_loss: 0.0139 - 44ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "8/8 - 0s - loss: 0.0165 - val_loss: 0.0139 - 50ms/epoch - 6ms/step\n",
            "Epoch 54/100\n",
            "8/8 - 0s - loss: 0.0179 - val_loss: 0.0140 - 40ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "8/8 - 0s - loss: 0.0175 - val_loss: 0.0138 - 48ms/epoch - 6ms/step\n",
            "Epoch 56/100\n",
            "8/8 - 0s - loss: 0.0159 - val_loss: 0.0140 - 51ms/epoch - 6ms/step\n",
            "Epoch 57/100\n",
            "8/8 - 0s - loss: 0.0163 - val_loss: 0.0138 - 58ms/epoch - 7ms/step\n",
            "Epoch 58/100\n",
            "8/8 - 0s - loss: 0.0154 - val_loss: 0.0140 - 48ms/epoch - 6ms/step\n",
            "Epoch 59/100\n",
            "8/8 - 0s - loss: 0.0188 - val_loss: 0.0142 - 58ms/epoch - 7ms/step\n",
            "Epoch 60/100\n",
            "8/8 - 0s - loss: 0.0159 - val_loss: 0.0140 - 49ms/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "8/8 - 0s - loss: 0.0176 - val_loss: 0.0139 - 48ms/epoch - 6ms/step\n",
            "Epoch 62/100\n",
            "8/8 - 0s - loss: 0.0202 - val_loss: 0.0138 - 42ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "8/8 - 0s - loss: 0.0151 - val_loss: 0.0137 - 43ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "8/8 - 0s - loss: 0.0170 - val_loss: 0.0139 - 67ms/epoch - 8ms/step\n",
            "Epoch 65/100\n",
            "8/8 - 0s - loss: 0.0163 - val_loss: 0.0140 - 57ms/epoch - 7ms/step\n",
            "Epoch 66/100\n",
            "8/8 - 0s - loss: 0.0179 - val_loss: 0.0138 - 47ms/epoch - 6ms/step\n",
            "Epoch 67/100\n",
            "8/8 - 0s - loss: 0.0176 - val_loss: 0.0135 - 43ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "8/8 - 0s - loss: 0.0162 - val_loss: 0.0138 - 52ms/epoch - 7ms/step\n",
            "Epoch 69/100\n",
            "8/8 - 0s - loss: 0.0193 - val_loss: 0.0136 - 41ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "8/8 - 0s - loss: 0.0138 - val_loss: 0.0136 - 46ms/epoch - 6ms/step\n",
            "Epoch 71/100\n",
            "8/8 - 0s - loss: 0.0148 - val_loss: 0.0136 - 45ms/epoch - 6ms/step\n",
            "Epoch 72/100\n",
            "8/8 - 0s - loss: 0.0144 - val_loss: 0.0137 - 56ms/epoch - 7ms/step\n",
            "Epoch 73/100\n",
            "8/8 - 0s - loss: 0.0149 - val_loss: 0.0137 - 51ms/epoch - 6ms/step\n",
            "Epoch 74/100\n",
            "8/8 - 0s - loss: 0.0156 - val_loss: 0.0136 - 53ms/epoch - 7ms/step\n",
            "Epoch 75/100\n",
            "8/8 - 0s - loss: 0.0151 - val_loss: 0.0135 - 41ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "8/8 - 0s - loss: 0.0176 - val_loss: 0.0133 - 50ms/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "8/8 - 0s - loss: 0.0175 - val_loss: 0.0136 - 50ms/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "8/8 - 0s - loss: 0.0164 - val_loss: 0.0136 - 51ms/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "8/8 - 0s - loss: 0.0176 - val_loss: 0.0143 - 40ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "8/8 - 0s - loss: 0.0156 - val_loss: 0.0138 - 49ms/epoch - 6ms/step\n",
            "Epoch 81/100\n",
            "8/8 - 0s - loss: 0.0191 - val_loss: 0.0133 - 48ms/epoch - 6ms/step\n",
            "Epoch 82/100\n",
            "8/8 - 0s - loss: 0.0163 - val_loss: 0.0131 - 47ms/epoch - 6ms/step\n",
            "Epoch 83/100\n",
            "8/8 - 0s - loss: 0.0178 - val_loss: 0.0132 - 49ms/epoch - 6ms/step\n",
            "Epoch 84/100\n",
            "8/8 - 0s - loss: 0.0154 - val_loss: 0.0137 - 43ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "8/8 - 0s - loss: 0.0172 - val_loss: 0.0135 - 60ms/epoch - 7ms/step\n",
            "Epoch 86/100\n",
            "8/8 - 0s - loss: 0.0152 - val_loss: 0.0132 - 42ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "8/8 - 0s - loss: 0.0164 - val_loss: 0.0133 - 47ms/epoch - 6ms/step\n",
            "Epoch 88/100\n",
            "8/8 - 0s - loss: 0.0172 - val_loss: 0.0132 - 47ms/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "8/8 - 0s - loss: 0.0140 - val_loss: 0.0131 - 41ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "8/8 - 0s - loss: 0.0161 - val_loss: 0.0131 - 46ms/epoch - 6ms/step\n",
            "Epoch 91/100\n",
            "8/8 - 0s - loss: 0.0166 - val_loss: 0.0130 - 47ms/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "8/8 - 0s - loss: 0.0155 - val_loss: 0.0132 - 51ms/epoch - 6ms/step\n",
            "Epoch 93/100\n",
            "8/8 - 0s - loss: 0.0164 - val_loss: 0.0133 - 45ms/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "8/8 - 0s - loss: 0.0170 - val_loss: 0.0135 - 43ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "8/8 - 0s - loss: 0.0154 - val_loss: 0.0139 - 47ms/epoch - 6ms/step\n",
            "Epoch 96/100\n",
            "8/8 - 0s - loss: 0.0140 - val_loss: 0.0135 - 50ms/epoch - 6ms/step\n",
            "Epoch 97/100\n",
            "8/8 - 0s - loss: 0.0155 - val_loss: 0.0134 - 44ms/epoch - 6ms/step\n",
            "Epoch 98/100\n",
            "8/8 - 0s - loss: 0.0154 - val_loss: 0.0135 - 48ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "8/8 - 0s - loss: 0.0146 - val_loss: 0.0137 - 46ms/epoch - 6ms/step\n",
            "Epoch 100/100\n",
            "8/8 - 0s - loss: 0.0156 - val_loss: 0.0135 - 51ms/epoch - 6ms/step\n",
            "Epoch 1/100\n",
            "8/8 - 3s - loss: 0.2761 - val_loss: 0.1209 - 3s/epoch - 331ms/step\n",
            "Epoch 2/100\n",
            "8/8 - 0s - loss: 0.1296 - val_loss: 0.0459 - 48ms/epoch - 6ms/step\n",
            "Epoch 3/100\n",
            "8/8 - 0s - loss: 0.0507 - val_loss: 0.0171 - 44ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "8/8 - 0s - loss: 0.0209 - val_loss: 0.0200 - 43ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "8/8 - 0s - loss: 0.0232 - val_loss: 0.0252 - 44ms/epoch - 6ms/step\n",
            "Epoch 6/100\n",
            "8/8 - 0s - loss: 0.0246 - val_loss: 0.0214 - 48ms/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "8/8 - 0s - loss: 0.0199 - val_loss: 0.0179 - 54ms/epoch - 7ms/step\n",
            "Epoch 8/100\n",
            "8/8 - 0s - loss: 0.0187 - val_loss: 0.0163 - 42ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "8/8 - 0s - loss: 0.0213 - val_loss: 0.0160 - 40ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "8/8 - 0s - loss: 0.0181 - val_loss: 0.0164 - 46ms/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "8/8 - 0s - loss: 0.0186 - val_loss: 0.0164 - 54ms/epoch - 7ms/step\n",
            "Epoch 12/100\n",
            "8/8 - 0s - loss: 0.0192 - val_loss: 0.0163 - 48ms/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "8/8 - 0s - loss: 0.0201 - val_loss: 0.0162 - 53ms/epoch - 7ms/step\n",
            "Epoch 14/100\n",
            "8/8 - 0s - loss: 0.0187 - val_loss: 0.0162 - 49ms/epoch - 6ms/step\n",
            "Epoch 15/100\n",
            "8/8 - 0s - loss: 0.0183 - val_loss: 0.0160 - 51ms/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "8/8 - 0s - loss: 0.0182 - val_loss: 0.0158 - 48ms/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "8/8 - 0s - loss: 0.0184 - val_loss: 0.0159 - 51ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "8/8 - 0s - loss: 0.0165 - val_loss: 0.0160 - 48ms/epoch - 6ms/step\n",
            "Epoch 19/100\n",
            "8/8 - 0s - loss: 0.0168 - val_loss: 0.0156 - 59ms/epoch - 7ms/step\n",
            "Epoch 20/100\n",
            "8/8 - 0s - loss: 0.0197 - val_loss: 0.0153 - 46ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "8/8 - 0s - loss: 0.0162 - val_loss: 0.0151 - 47ms/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "8/8 - 0s - loss: 0.0179 - val_loss: 0.0150 - 45ms/epoch - 6ms/step\n",
            "Epoch 23/100\n",
            "8/8 - 0s - loss: 0.0185 - val_loss: 0.0152 - 41ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "8/8 - 0s - loss: 0.0178 - val_loss: 0.0151 - 47ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "8/8 - 0s - loss: 0.0185 - val_loss: 0.0150 - 55ms/epoch - 7ms/step\n",
            "Epoch 26/100\n",
            "8/8 - 0s - loss: 0.0174 - val_loss: 0.0151 - 50ms/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "8/8 - 0s - loss: 0.0174 - val_loss: 0.0149 - 49ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "8/8 - 0s - loss: 0.0184 - val_loss: 0.0146 - 71ms/epoch - 9ms/step\n",
            "Epoch 29/100\n",
            "8/8 - 0s - loss: 0.0175 - val_loss: 0.0147 - 53ms/epoch - 7ms/step\n",
            "Epoch 30/100\n",
            "8/8 - 0s - loss: 0.0167 - val_loss: 0.0146 - 49ms/epoch - 6ms/step\n",
            "Epoch 31/100\n",
            "8/8 - 0s - loss: 0.0160 - val_loss: 0.0146 - 53ms/epoch - 7ms/step\n",
            "Epoch 32/100\n",
            "8/8 - 0s - loss: 0.0158 - val_loss: 0.0145 - 46ms/epoch - 6ms/step\n",
            "Epoch 33/100\n",
            "8/8 - 0s - loss: 0.0179 - val_loss: 0.0146 - 48ms/epoch - 6ms/step\n",
            "Epoch 34/100\n",
            "8/8 - 0s - loss: 0.0168 - val_loss: 0.0147 - 50ms/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "8/8 - 0s - loss: 0.0156 - val_loss: 0.0143 - 46ms/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "8/8 - 0s - loss: 0.0171 - val_loss: 0.0142 - 45ms/epoch - 6ms/step\n",
            "Epoch 37/100\n",
            "8/8 - 0s - loss: 0.0171 - val_loss: 0.0145 - 48ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "8/8 - 0s - loss: 0.0153 - val_loss: 0.0146 - 52ms/epoch - 7ms/step\n",
            "Epoch 39/100\n",
            "8/8 - 0s - loss: 0.0157 - val_loss: 0.0142 - 50ms/epoch - 6ms/step\n",
            "Epoch 40/100\n",
            "8/8 - 0s - loss: 0.0157 - val_loss: 0.0140 - 45ms/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "8/8 - 0s - loss: 0.0149 - val_loss: 0.0141 - 41ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "8/8 - 0s - loss: 0.0166 - val_loss: 0.0139 - 40ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "8/8 - 0s - loss: 0.0164 - val_loss: 0.0138 - 48ms/epoch - 6ms/step\n",
            "Epoch 44/100\n",
            "8/8 - 0s - loss: 0.0159 - val_loss: 0.0139 - 45ms/epoch - 6ms/step\n",
            "Epoch 45/100\n",
            "8/8 - 0s - loss: 0.0183 - val_loss: 0.0140 - 48ms/epoch - 6ms/step\n",
            "Epoch 46/100\n",
            "8/8 - 0s - loss: 0.0146 - val_loss: 0.0138 - 50ms/epoch - 6ms/step\n",
            "Epoch 47/100\n",
            "8/8 - 0s - loss: 0.0161 - val_loss: 0.0140 - 46ms/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "8/8 - 0s - loss: 0.0168 - val_loss: 0.0140 - 47ms/epoch - 6ms/step\n",
            "Epoch 49/100\n",
            "8/8 - 0s - loss: 0.0156 - val_loss: 0.0139 - 49ms/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "8/8 - 0s - loss: 0.0174 - val_loss: 0.0138 - 54ms/epoch - 7ms/step\n",
            "Epoch 51/100\n",
            "8/8 - 0s - loss: 0.0173 - val_loss: 0.0139 - 50ms/epoch - 6ms/step\n",
            "Epoch 52/100\n",
            "8/8 - 0s - loss: 0.0170 - val_loss: 0.0137 - 56ms/epoch - 7ms/step\n",
            "Epoch 53/100\n",
            "8/8 - 0s - loss: 0.0166 - val_loss: 0.0135 - 53ms/epoch - 7ms/step\n",
            "Epoch 54/100\n",
            "8/8 - 0s - loss: 0.0145 - val_loss: 0.0136 - 45ms/epoch - 6ms/step\n",
            "Epoch 55/100\n",
            "8/8 - 0s - loss: 0.0143 - val_loss: 0.0139 - 47ms/epoch - 6ms/step\n",
            "Epoch 56/100\n",
            "8/8 - 0s - loss: 0.0149 - val_loss: 0.0137 - 60ms/epoch - 7ms/step\n",
            "Epoch 57/100\n",
            "8/8 - 0s - loss: 0.0158 - val_loss: 0.0134 - 56ms/epoch - 7ms/step\n",
            "Epoch 58/100\n",
            "8/8 - 0s - loss: 0.0141 - val_loss: 0.0134 - 48ms/epoch - 6ms/step\n",
            "Epoch 59/100\n",
            "8/8 - 0s - loss: 0.0153 - val_loss: 0.0140 - 50ms/epoch - 6ms/step\n",
            "Epoch 60/100\n",
            "8/8 - 0s - loss: 0.0158 - val_loss: 0.0136 - 54ms/epoch - 7ms/step\n",
            "Epoch 61/100\n",
            "8/8 - 0s - loss: 0.0153 - val_loss: 0.0134 - 51ms/epoch - 6ms/step\n",
            "Epoch 62/100\n",
            "8/8 - 0s - loss: 0.0153 - val_loss: 0.0135 - 51ms/epoch - 6ms/step\n",
            "Epoch 63/100\n",
            "8/8 - 0s - loss: 0.0145 - val_loss: 0.0137 - 50ms/epoch - 6ms/step\n",
            "Epoch 64/100\n",
            "8/8 - 0s - loss: 0.0161 - val_loss: 0.0134 - 51ms/epoch - 6ms/step\n",
            "Epoch 65/100\n",
            "8/8 - 0s - loss: 0.0150 - val_loss: 0.0134 - 45ms/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "8/8 - 0s - loss: 0.0165 - val_loss: 0.0135 - 44ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "8/8 - 0s - loss: 0.0174 - val_loss: 0.0135 - 52ms/epoch - 7ms/step\n",
            "Epoch 68/100\n",
            "8/8 - 0s - loss: 0.0153 - val_loss: 0.0136 - 49ms/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "8/8 - 0s - loss: 0.0154 - val_loss: 0.0135 - 52ms/epoch - 7ms/step\n",
            "Epoch 70/100\n",
            "8/8 - 0s - loss: 0.0152 - val_loss: 0.0137 - 51ms/epoch - 6ms/step\n",
            "Epoch 71/100\n",
            "8/8 - 0s - loss: 0.0171 - val_loss: 0.0133 - 50ms/epoch - 6ms/step\n",
            "Epoch 72/100\n",
            "8/8 - 0s - loss: 0.0143 - val_loss: 0.0134 - 55ms/epoch - 7ms/step\n",
            "Epoch 73/100\n",
            "8/8 - 0s - loss: 0.0150 - val_loss: 0.0135 - 63ms/epoch - 8ms/step\n",
            "Epoch 74/100\n",
            "8/8 - 0s - loss: 0.0137 - val_loss: 0.0133 - 47ms/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "8/8 - 0s - loss: 0.0154 - val_loss: 0.0136 - 54ms/epoch - 7ms/step\n",
            "Epoch 76/100\n",
            "8/8 - 0s - loss: 0.0164 - val_loss: 0.0138 - 60ms/epoch - 7ms/step\n",
            "Epoch 77/100\n",
            "8/8 - 0s - loss: 0.0154 - val_loss: 0.0133 - 52ms/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "8/8 - 0s - loss: 0.0138 - val_loss: 0.0132 - 52ms/epoch - 7ms/step\n",
            "Epoch 79/100\n",
            "8/8 - 0s - loss: 0.0137 - val_loss: 0.0133 - 51ms/epoch - 6ms/step\n",
            "Epoch 80/100\n",
            "8/8 - 0s - loss: 0.0141 - val_loss: 0.0134 - 48ms/epoch - 6ms/step\n",
            "Epoch 81/100\n",
            "8/8 - 0s - loss: 0.0150 - val_loss: 0.0135 - 46ms/epoch - 6ms/step\n",
            "Epoch 82/100\n",
            "8/8 - 0s - loss: 0.0153 - val_loss: 0.0136 - 47ms/epoch - 6ms/step\n",
            "Epoch 83/100\n",
            "8/8 - 0s - loss: 0.0158 - val_loss: 0.0132 - 45ms/epoch - 6ms/step\n",
            "Epoch 84/100\n",
            "8/8 - 0s - loss: 0.0153 - val_loss: 0.0130 - 53ms/epoch - 7ms/step\n",
            "Epoch 85/100\n",
            "8/8 - 0s - loss: 0.0141 - val_loss: 0.0133 - 48ms/epoch - 6ms/step\n",
            "Epoch 86/100\n",
            "8/8 - 0s - loss: 0.0153 - val_loss: 0.0134 - 45ms/epoch - 6ms/step\n",
            "Epoch 87/100\n",
            "8/8 - 0s - loss: 0.0148 - val_loss: 0.0132 - 52ms/epoch - 7ms/step\n",
            "Epoch 88/100\n",
            "8/8 - 0s - loss: 0.0145 - val_loss: 0.0134 - 49ms/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "8/8 - 0s - loss: 0.0145 - val_loss: 0.0136 - 65ms/epoch - 8ms/step\n",
            "Epoch 90/100\n",
            "8/8 - 0s - loss: 0.0154 - val_loss: 0.0131 - 56ms/epoch - 7ms/step\n",
            "Epoch 91/100\n",
            "8/8 - 0s - loss: 0.0132 - val_loss: 0.0128 - 47ms/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "8/8 - 0s - loss: 0.0152 - val_loss: 0.0131 - 54ms/epoch - 7ms/step\n",
            "Epoch 93/100\n",
            "8/8 - 0s - loss: 0.0145 - val_loss: 0.0134 - 47ms/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "8/8 - 0s - loss: 0.0158 - val_loss: 0.0131 - 50ms/epoch - 6ms/step\n",
            "Epoch 95/100\n",
            "8/8 - 0s - loss: 0.0132 - val_loss: 0.0132 - 55ms/epoch - 7ms/step\n",
            "Epoch 96/100\n",
            "8/8 - 0s - loss: 0.0140 - val_loss: 0.0134 - 50ms/epoch - 6ms/step\n",
            "Epoch 97/100\n",
            "8/8 - 0s - loss: 0.0148 - val_loss: 0.0130 - 47ms/epoch - 6ms/step\n",
            "Epoch 98/100\n",
            "8/8 - 0s - loss: 0.0145 - val_loss: 0.0130 - 47ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "8/8 - 0s - loss: 0.0157 - val_loss: 0.0132 - 45ms/epoch - 6ms/step\n",
            "Epoch 100/100\n",
            "8/8 - 0s - loss: 0.0144 - val_loss: 0.0129 - 60ms/epoch - 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_df = pd.DataFrame.from_dict(models, orient='index', columns=['RMSE', 'MSE', 'MAE', 'R_sq', 'MAPE'])\n",
        "models_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "_icP2_jJgL2C",
        "outputId": "efd8382f-ce75-4bc4-e2a0-be39d801bf2b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>R_sq</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4155.051531</td>\n",
              "      <td>1.726445e+07</td>\n",
              "      <td>3356.115623</td>\n",
              "      <td>0.173938</td>\n",
              "      <td>0.194740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>4158.991754</td>\n",
              "      <td>1.729721e+07</td>\n",
              "      <td>3353.187823</td>\n",
              "      <td>0.172371</td>\n",
              "      <td>0.198293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>4068.715886</td>\n",
              "      <td>1.655445e+07</td>\n",
              "      <td>3255.219831</td>\n",
              "      <td>0.207910</td>\n",
              "      <td>0.189771</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            RMSE           MSE          MAE      R_sq      MAPE\n",
              "30   4155.051531  1.726445e+07  3356.115623  0.173938  0.194740\n",
              "50   4158.991754  1.729721e+07  3353.187823  0.172371  0.198293\n",
              "100  4068.715886  1.655445e+07  3255.219831  0.207910  0.189771"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}